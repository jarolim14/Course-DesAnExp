---
title: "Design and Analysis of Experiments - Session 1"
author: "lukas"
date: "`r Sys.Date()`"
format:
  html:
    self-contained: true
    toc: true
    code-fold: true
    code-summary: "Show code"
knitr:
  opts_chunk:      ########## set global options ############
    collapse: true # keep code from blocks together (if shown)
    echo: true     #  show code
    message: true  # show messages
    warning: true  # show warnings
    error: true    # show error messages
    comment: ""    # don't show ## with printed output
    R.options:
      
        digits: 3    # round to three digits
editor: visual
bibliography: [references.bib, packages.bib]
csl: the-new-england-journal-of-medicine.csl
---

```{r}
#| label: tidyverse
#| echo: false

options(scipen = 1, digits = 2)

library(conflicted)
conflict_prefer("filter", "dplyr", quiet = TRUE)
conflict_prefer("lag", "dplyr", quiet = TRUE)

suppressPackageStartupMessages(library(tidyverse))

# suppress "`summarise()` has grouped output by " messages
options(dplyr.summarise.inform = FALSE)

```

Analyses were conducted with `r stringr::word(R.Version()$version.string, 1, 3)` with the `tidyverse` (`r packageVersion("tidyverse")`), `rUM` (`r packageVersion("rUM")`), `table1` (`r packageVersion("table1")`) packages used to preprocess and summarize data.[@R-base; @R-tidyverse; @tidyverse2019; @R-rUM; @R-table1]

# Exercise Session 1

## Exercise 1

A two sample t-test is performed with hypotheses

> H0:μx=μy Ha:μx≠μy

Given a p-value of 0.09, w*hat can be concluded on a 10% significance level?*

**Solution**

> Since the p-value lies below the significance level, we can reject H0. The p-value is the likelihood of the observed data, given that the null hypothesis is true. It also is the likelihood of falsely rejecting the null hypothesis. If the likelihood of falsely rejecting the null is smaller than the significance level, we conclude the e.g. the sample means are not equal.

[![](supplementary/p_value.png)](p_value)

## Exercise 2

From `t.test` for a two sample t-test with the usual null-hypothesis of equal means and a two-sided alternative, the 95% confidence interval is given as:

$CI(−0.01\;;\;1.01)$

*What can be concluded about the p-value for the test?*

**Solution**

> If the CI includes 0, the p-value will be bigger than the significance level and $H_0$ cannot be rejected. Note that the CI of a t-test is an estimate of the difference between the two means. If this inlcudes 0, this is evidence that the means are equal ($H_0$). (What might change if we used a 90% confidence level?)

## Exercise 3

Copy the following code into R, run the code and inspect the resulting objects

```{r}
#| code-fold: false
x <- c(11.38, 15.4, 10.41, 12.7, 7.47, 11.68, 14.26, 11.09, 10.2, 
13.45)
y <- c(9.85, 9.73, 9.74, 8.65, 9.71, 10.3, 9.04, 8.02, 9.79, 9.79)
```

### 3a

Compute sample means and variance for the two samples

**Solution**

*use `mean()` and `var()`*

| var | mean        | variance             |
|-----|-------------|----------------------|
| x   | `r mean(x)` | `r round(var(x),3 )` |
| y   | `r mean(y)` | `r round(var(y),3 )` |

### 3b

Formulate a single sample t-test for x with $μ_0=10$ with a two-sided alternative

**Solution**

The null hypthesis is that `mean(x)` equals ten (assuming normal distribution).

$$
H_0 : µ = 10 \; ; \; H_a : µ_x ≠ 10
$$

### 3c

Do the corresponding t-test with R and interpret the results.

**Solution**

```{r}
res = t.test(x, mu=10)
print(res)
```

The p-value is `r round(res$p.value, 3)` and therefore significant at an alpha level of .05.

Assessing the normality assumption of x:

```{r}
qqnorm(x)
qqline(x)
```

The residuals seem to be normally distributed.

### 3d

Formulate a t-test comparing x and y with a two-sided alternative

**Solution**

$$
H_0 : µ_x = µ_y ; H_a : µ_x ≠ µ_y
$$

### 3e

Do the t-test assuming equal variances and interpret the results

**Solution**

```{r}
res <- t.test(x,y, var.equal = TRUE)

print(res)
```

The p-value is `r round(res$p.value, 3)` and therefore significant at an alpha level of .05.

Testing normality:

```{r}
### Split the sqreen
par(mfrow=c(1,2)) 
### Should be straight lines (note that with small samples it may be difficult to assess - consider Wally-plot)
qqnorm(x)
qqline(x)
qqnorm(y)
qqline(y)
```

### 3f

Compare the variances of the two samples with a F-test using a two-sided alternative

**Solution**

```{r}
res <- var.test(x,y, alternative = "two.sided")
print(res)
```

Considering the p-value of `r round(res$p.value, 3)`, we can assume that the variances are not equal.

### 3f2

Do the t-test not assuming equal variances and compare with the t-test performed with the assumption of equal variances

Assuming **unequal** variances, the p-value becomes larger (still significant at alpha = .05). Since the pooled sample variance provides a higher precision estimate of variance than the individual sample variances, we arrive at a conclusion with higher certainty (So which CI do you expect to be bigger, var.equal = FALSE or var.equal = TRUE?).\
We also see a difference in the degrees of freedom.

```{r}
res <- t.test(x,y, var.equal = FALSE)

print(res)
```

### 3g

Assume now that the 10 samples in x and y were from the same 10 persons. Formulate an appropriate test for comparing the means and do the corresponding test.

**Solution**

We need to do a paired-sample t-test that assesses whether the means differ per person. So, we calculate the difference for every person( $d_i = x_i - y_i$ ) and calculate the average ($μ_d$). Then we assess whether this is differen from 0. If that is the case, we reject $H_0$. The differences are assumed to come from a normal distribution.

The hypotheses are:

$$
H_0: μ_d=0 \:\:\:\:\:\:\:\:\:\: H_a:μ_d≠0
$$

### 3h

Do the paired t-test with the *x* and *y* vectors defined above directly in a t-test

**Solution**

```{r}
res = t.test(x,y, paired = TRUE)
print(res)
```

The p-value is `r round(res$p.value, 3)` and therefore significant at an alpha level of .05.

Note that the degrees of freedom are only 9 since nr of independent observations are only 10 in this case.

### 3i

Do the paired t-test on the differences $d$, which can be computed by

```{r}
#| code-fold: false

d = x - y
```

**Solution**

```{r}
res = t.test(d)
print(res)
```

The p-value is `r round(res$p.value, 3)` again, so exactly what was expected. (The t.test() functions default for mu is 0, mu is indicating the true value of the mean (or difference in means if you are performing a two sample test. more [here](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/t.test))

## Exercise 4

The following quantities are provided to you:

| Sample | Mean | Variance |
|--------|------|----------|
| 1      | 20.3 | 3.2      |
| 2      | 15.4 | 2.7      |

Based on this information (assuming that the normality assumptions are fulfilled) can you do a two sample t-test?

**Solution**

It is not possible since the sample size is unknown.

## Exercise 5

The following quantities are provided to you:

| Sample | Mean | Variance | N   |
|--------|------|----------|-----|
| 1      | 20.3 | 3.2      | 23  |
| 2      | 15.4 | 2.7      | 22  |

Assume the variances are equal and the sample sizes are 23 and 22 for sample 1 and 2, respectively. MANUALLY perform a two-sample t-test with the usual null-hypothesis and a two-sided alternative

**Solution**

Step 1: Pooled Standard Deviation (variances are equal)

The pooled SD is a weighted average of the sample SDs.

Formula:

$$
S^2_p = \frac{(n_1 - 1)s^2_1 + (n_2)s^2_2} {n_1 + n_2 - 2}  = \frac{(23−1)3.2+(22−1)2.7}{23+22−2} = 2.96
$$

```{r}
var1 <- 3.2
var2 <- 2.7

n1 <- 23
n2 <- 22

pooled_var = ((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2)
  
pooled_sd = sqrt(pooled_var)

sprintf('Var: %.3f, SD: %.3f', pooled_var, pooled_sd)
```

The pooled variance equals `r pooled_var`. Now, we can compute the test-statistic $t$.

Step 2: Test Statistic

The test statistic can be used to see where on the t+distribution our observation falls. It can also be used to see whether it is smaller/bigger than some critical value ($\alpha$).

The formula:

$$
t_0=\frac{\hat{x}_1−\hat{x}_2}{\sqrt{s^2_p (1/n_1+1/n_2)}} = \frac{20.3−15.4}{\sqrt{2.96(1/23+1/22)}} = 9.5
$$

```{r}
x1 = 20.3
x2 = 15.4

t = (x1-x2) / sqrt(pooled_var*(1/23 + 1/22))
sprintf('t-statistic: %.3f', t)
```

```{r}
#create density plots
curve(dt(x, df=6), from=-4, to=4, col='blue') 
curve(dt(x, df=43), from=-4, to=4, col='red', add=TRUE)
curve(dt(x, df=500), from=-4, to=4, col='green', add=TRUE)

#add legend
legend(-4, .3, legend=c("df=5", "df=43", "df=500"),
       col=c("blue", "red", "green"), lty=1, cex=1.2)
```

Step 3: P-Value

**dt()**, **qt()**, **pt()**, and **rt()** are formula for the Student t distribution. [Here](https://www.statology.org/working-with-the-student-t-distribution-in-r-dt-qt-pt-rt/) is more info. pt() returns the area to the left of a given value *x* in the Student t distribution

```{r}
df <- 23+22-2
print(pt(t, df))

```

The area of the distribution lies (almost) entirely to the left of the calculated t-value. Therefore, the test is significant. Since the critical value is .05, any value greater than 0.975 is considered significant.

We can also compare to the critical value:

```{r}
cv = qt(1-.05/2, df)
sprintf('The critical value is %f, which is smaller than %f. We reject H0.', cv, t)
```

This is a (simplified) visualization of the results:

```{r}
# generate data from mean and sd
curve(dt(x, df=43), from=-t-1, to=t+1)
abline(v = c(cv, -cv, t, -t), col = c("red","red","darkgreen", "darkgreen"))

```

## Exercise 6

In an experiment with a single factor with 5 levels, each factor level is replicated 4 times in a completely randomized order. The F-statistic is .76, what is the corresponding p-value?

Hint: run `help(pf)`

**Solution**

We use the pf() function where df1 is the number of factor levels - 1 ($5-1 = 4$) and df2 is the number of total observations ($n=4*5 = 20$) minus the number of factor levels ($a = 5$). So $df2=(4*5) - 5 = 15$

```{r}
f = 3.76
df1 = 4
df2 = 15
print(pf(f, df1 = df1, df2 = df2, lower.tail = FALSE))
print(pf(f,df1,df2))
```

## Exercise 7

Reconsider the previous question. Assume the **same** F-statistic, the **same** number of factor levels. What happens to the p-value if *n* was in fact lower? What happens if *n* was higher?

**Solution**

If n was lower, the p-value would be higher. The larger n, the smaller the p-value.

It makes intuitive if you consider that the credibility increases if your sample size increases.

lower n:

```{r}
df2 = 5*2-5

print(pf(f, df1 = df1, df2 = df2, lower.tail = FALSE))

```

Higher n:

```{r}
df2 = 5*20-5

print(pf(f, df1 = df1, df2 = df2, lower.tail = FALSE))
```

## Exercise 8

A partially filled out ANOVA is given below.

| Source    | DF       | Sum of Squares | Mean Square | F        | P         |
|-----------|----------|----------------|-------------|----------|-----------|
| Treatment | 4        | 100            | ? (25)      | ? (4.55) | ? (.0089) |
| Error     | ? *(20)* | ? *(110)*      | ? (5.5)     |          |           |
| Total     | 24       | 210            |             |          |           |

### 8a

How many treatment levels do we have?

**Solution**

The degrees of freedom for Treatment is a−1, thus the number of levels is

$4+1=5$

### 8b

How many replicates?

**Solution**

There is a total of $24+1=25$ observations. From the previous question we know that the number of treatment levels is 5. Thus, there are 5 replicates, since $5⋅5=25$.

(if there are 5 different treatments, in total there are 25 participants, how many participants are in a single treatment group? --\> $5*x=25$)

### 8c

What is the mean square for Treatment?

**Solution**

$MS_t = SS_t / (a-1)$ = `r 100 / (5-1)`

### 8d

What is the mean square for Error?

**Solution**

Step 1: $SS_E = 210 - 100 = 110$

Step 2: $MS_E = SS_E / (N-a) = 110 / (25-5) =$ `r 110 / (25-5)`

### 8e

What is the F-statistic?

**Solution**

The F-statistic is the ratio between the mean squares or the ratio of the between-group variance to the within-group variance. The between-group variance measures the variability in the data that is due to differences between the group means, while the within-group variance measures the variability in the data that is due to differences within each group. The greater the between group variance compare to the within group difference, the more confident we are that treatment has an effect.

$F = 25/5.5 = 4.55$

### 8f

What is the p-value?

**Solution**

The p-value can be computed by plugging the F-statistic into the proper F-distribution in R (remember to enter the degrees of freedom correct)

```{r}
p_value <- pf(4.55, 4, 20, lower.tail = FALSE)
print(p_value)
```

### 8g

What can be concluded about the treatment means at a 5% significance level?

**Solution**

On a 5% significance level we reject the null-hypothesis, which is that ALL treatment means are equal. Thus, at least one treatment mean differs from the others.

## Exercise 9

Run the following code in R

```{r}
#| code-fold: false

dat <- data.frame(yield=c(8.19, 10.42, 11.63,  6.48, 10.64, 10.76, 12.14, 12.18, 12.15, 11.66, 12.28, 11.50, 10.84, 12.10, 13.44, 11.83, 11.23, 10.63),
                  Treatment=rep(LETTERS[1:3],each=6))
dat$Treatment <- factor(dat$Treatment)
```

### 9a

Analyse the data assuming a completely randomized design

**Solution**

Using a linear regression:

```{r}
res.reg <- lm(yield~Treatment, data=dat)
summary(res.reg)
```

Using ANOVA:

```{r}
res.aov <- aov(yield~Treatment, data=dat)
summary(res.aov)
```

### 9b

Check assumptions

**Solution**

> Linearity (of the residuals)

```{r}
qqnorm(residuals(res.reg))
qqline(residuals(res.reg))
```

The residuals appear to be on a straight line ( the line represents a perfect normal distribution) . This is evidence for normality.

> Constant Variance (Homoscedasticity)

plotting the residual vs. the fitted values can show whether variance in greater for a specific treatment.

```{r}
plot(fitted(res.reg),residuals(res.reg))
```

Variance might be greater for the first treatment. A plot without any structure would be evidence for normality.

### 9c

Which treatment seems to give the highest yield?

**Solution**

Different solutions possible.

Looking at regression model:

```{r}
summary(res.reg)
```

From the estimated coefficients, Treatment B seems to be the best, followed by C. (The mean for treatment A is the intercept, adding the estimates gives the means for B and C respectively)

```{r}
dat$fitted <- predict(res.reg)
boxplot(dat$fitted~dat$Treatment)
```

### 9d

Perform all pairwise comparisons using *TukeyHSD*. What can be seen from the comparisons?

**Solution**

Pairwise comparisons:

```{r}
TukeyHSD(res.aov, "Treatment")
```

A is sig. smaller than B and C. B and C do not sig. differ.

Visualized with 95% CI:

```{r}
plot(TukeyHSD(res.aov,"Treatment"))
```

# Session Info

```{r}
sessionInfo()
```

# References {.unnumbered}

```{r}
#| include: false

# automatically create a bib database for loaded R packages & rUM
knitr::write_bib(
  c(
    .packages(),
    "rUM",
    "table1"
  ),
  "packages.bib"
)
```
